{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5ccd237",
        "outputId": "aeda5ad7-8032-4292-e2ef-8fb5ca021369"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NW5C1VBv0Ytj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch\n",
        "from scipy.linalg import sqrtm\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FpMGH4LJ0Ytk"
      },
      "outputs": [],
      "source": [
        "def plot_batch_images(images, labels):\n",
        "    batch_size = images.shape[0]\n",
        "    nrow = int(np.sqrt(batch_size))\n",
        "    grid_img = torchvision.utils.make_grid(images, nrow=nrow, normalize=True)  # Arrange images in grid\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(grid_img.permute(1, 2, 0))  # Convert from (C, H, W) to (H, W, C)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"MNIST Batch Samples\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KLtC0MJP0Ytk"
      },
      "outputs": [],
      "source": [
        "\n",
        "class MNISTClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1),  # 28x28 â†’ 28x28\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # 28x28 â†’ 14x14\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1),  # 14x14 â†’ 14x14\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # 14x14 â†’ 7x7\n",
        "        )\n",
        "\n",
        "        classifier = nn.Sequential(\n",
        "                    nn.Flatten(),\n",
        "                    nn.Linear(64 * 7 * 7, 128),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(128, 10)\n",
        "        )\n",
        "        self.classifier = classifier.to(device)  # Moved to GPU\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.features(x)\n",
        "        logits = self.classifier(feats)\n",
        "        return logits, feats.view(x.size(0), -1)  # logits, feature_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NyHVmcvk0Ytk"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def train_mnist_classifier(n_epochs=5, save_path=\"mnist_classifier.pth\"):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    train_ds = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "    test_ds = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "    train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_ds, batch_size=64)\n",
        "\n",
        "    model = MNISTClassifier().to(device)\n",
        "    model = model.to(device)  # Moved to GPU\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    print(\"ðŸ“š Training MNIST classifier...\")\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            out, _ = model(x)\n",
        "            loss = criterion(out, y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs} âœ… Loss: {loss.item():.4f}\")\n",
        "\n",
        "    # Evaluate\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            out, _ = model(x)\n",
        "            pred = out.argmax(dim=1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    acc = correct / total\n",
        "    print(f\" Test Accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "    #torch.save(model.state_dict(), save_path)\n",
        "    #print(f\" Saved classifier to {save_path}\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlqA1tqL0Ytl",
        "outputId": "4ab30c9f-6d86-4009-fe88-442656d370ef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.91M/9.91M [00:02<00:00, 4.87MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28.9k/28.9k [00:00<00:00, 133kB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.65M/1.65M [00:01<00:00, 1.27MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.54k/4.54k [00:00<00:00, 6.11MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“š Training MNIST classifier...\n",
            "Epoch 1/5 âœ… Loss: 0.2158\n",
            "Epoch 2/5 âœ… Loss: 0.0046\n",
            "Epoch 3/5 âœ… Loss: 0.0157\n",
            "Epoch 4/5 âœ… Loss: 0.0396\n",
            "Epoch 5/5 âœ… Loss: 0.0253\n",
            " Test Accuracy: 99.08%\n"
          ]
        }
      ],
      "source": [
        "classifier = train_mnist_classifier(n_epochs=5)\n",
        "classifier = classifier.to(device)  # Moved to GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lPH-z1q10Ytl"
      },
      "outputs": [],
      "source": [
        "def load_MNISTdata():\n",
        "    data_dir = os.path.join(os.getcwd(), \"..\", \"data\", \"raw\")\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    train_dataset = datasets.MNIST(root=data_dir, train=True, transform=transform, download=True)\n",
        "    test_dataset = datasets.MNIST(root=data_dir, train=False, transform=transform, download=True)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "def loader_to_data(train_loader):\n",
        "    all_imgs = []\n",
        "\n",
        "    for imgs, _ in train_loader:\n",
        "        imgs = imgs.to(device)  # Move each batch to device\n",
        "        all_imgs.append(imgs)\n",
        "\n",
        "    data = torch.cat(all_imgs, dim=0)  # Already on device\n",
        "    print(f\"Loaded: {data.shape}\")\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN4PXpBQ0Ytl",
        "outputId": "436c638d-7a80-47a4-bafd-d52c571184f4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.91M/9.91M [00:01<00:00, 5.07MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28.9k/28.9k [00:00<00:00, 132kB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.65M/1.65M [00:01<00:00, 1.28MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.54k/4.54k [00:00<00:00, 6.59MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded: torch.Size([60000, 1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "train_loader, _ = load_MNISTdata()\n",
        "X_mnist = loader_to_data(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mq3TbqwE0Ytm"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, img_channels=3):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.utils.spectral_norm(nn.Conv2d(img_channels, 64, 4, stride=2, padding=1)),  # 28 â†’ 14\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.utils.spectral_norm(nn.Conv2d(64, 128, 4, stride=2, padding=1)),  # 14 â†’ 7\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.utils.spectral_norm(nn.Conv2d(128, 256, 3, stride=2, padding=1)),  # 7 â†’ 4\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.utils.spectral_norm(nn.Linear(256 * 4 * 4, 1))\n",
        "            # No Sigmoid!\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim=100, img_channels=3):\n",
        "        super(Generator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(z_dim, 256 * 7 * 7),\n",
        "            nn.BatchNorm1d(256 * 7 * 7),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Unflatten(1, (256, 7, 7)),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),  # 7x7 â†’ 14x14\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),  # 14x14 â†’ 28x28\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Conv2d(64, img_channels, kernel_size=3, stride=1, padding=1),\n",
        "            nn.Tanh()  # Output in [-1, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.net(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKvzePAo0Yto"
      },
      "source": [
        "Basic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FflQ2dlk6Rn7",
        "outputId": "0c4a0a2c-f4c1-4e02-ea65-2fd084b408e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler, TensorDataset\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set global device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "def train_BasicGAN(generator, discriminator, dataloader, lr=0.0001, criterion=None,\n",
        "                   latent_dim=100, n_epochs=20, plotit=False):\n",
        "\n",
        "    generator = generator.to(device)\n",
        "    discriminator = discriminator.to(device)\n",
        "\n",
        "    if criterion is None:\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    d_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    g_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "    d_losses, g_losses = [], []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        for imgs, _ in dataloader:\n",
        "            imgs = imgs.to(device)\n",
        "            batch_size = imgs.size(0)\n",
        "\n",
        "            real_labels = torch.ones(batch_size, 1, device=device)\n",
        "            fake_labels = torch.zeros(batch_size, 1, device=device)\n",
        "\n",
        "            # Train Discriminator\n",
        "            z = torch.randn(batch_size, latent_dim, device=device)\n",
        "            fake_imgs = generator(z)\n",
        "\n",
        "            d_optimizer.zero_grad()\n",
        "            real_loss = criterion(discriminator(imgs), real_labels)\n",
        "            fake_loss = criterion(discriminator(fake_imgs.detach()), fake_labels)\n",
        "            d_loss = real_loss + fake_loss\n",
        "            d_loss.backward()\n",
        "            d_optimizer.step()\n",
        "\n",
        "            # Train Generator\n",
        "            z = torch.randn(batch_size, latent_dim, device=device)\n",
        "            fake_imgs = generator(z)\n",
        "            g_optimizer.zero_grad()\n",
        "            g_loss = criterion(discriminator(fake_imgs), real_labels)\n",
        "            g_loss.backward()\n",
        "            g_optimizer.step()\n",
        "\n",
        "        d_losses.append(d_loss.item())\n",
        "        g_losses.append(g_loss.item())\n",
        "        print(f\"Epoch [{epoch+1}/{n_epochs}] | D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f}\")\n",
        "\n",
        "    if plotit:\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(d_losses, label=\"Discriminator Loss\")\n",
        "        plt.plot(g_losses, label=\"Generator Loss\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    return generator\n",
        "\n",
        "def generate_BasicGAN(generator, latent_dim=100, num_samples=16, plotit=False):\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(num_samples, latent_dim, device=device)\n",
        "        generated_images = generator(z)\n",
        "\n",
        "    if plotit:\n",
        "        plot_batch_images(generated_images, None)\n",
        "\n",
        "    return generated_images\n",
        "\n",
        "def get_classifier_features(classifier, data, batch_size=128):\n",
        "    classifier.eval()\n",
        "    classifier = classifier.to(device)\n",
        "    features = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(data), batch_size):\n",
        "            batch = torch.tensor(data[i:i+batch_size], dtype=torch.float32, device=device)\n",
        "            if batch.ndim == 3:\n",
        "                batch = batch.unsqueeze(1)\n",
        "            _, feats = classifier(batch)\n",
        "            features.append(feats.cpu())\n",
        "    return torch.cat(features, dim=0).numpy()\n",
        "\n",
        "def compute_fid(real_feats, fake_feats):\n",
        "    from scipy.linalg import sqrtm\n",
        "    mu1, mu2 = real_feats.mean(0), fake_feats.mean(0)\n",
        "    sigma1 = np.cov(real_feats, rowvar=False)\n",
        "    sigma2 = np.cov(fake_feats, rowvar=False)\n",
        "    covmean = sqrtm(sigma1 @ sigma2)\n",
        "    if np.iscomplexobj(covmean):\n",
        "        covmean = covmean.real\n",
        "    fid = np.sum((mu1 - mu2) ** 2) + np.trace(sigma1 + sigma2 - 2 * covmean)\n",
        "    return fid\n",
        "\n",
        "def compute_precision_recall(real_images, generated_images, k=3, eps=0.1):\n",
        "    from sklearn.neighbors import NearestNeighbors\n",
        "    from sklearn.preprocessing import normalize\n",
        "\n",
        "    def preprocess(images):\n",
        "        if isinstance(images, torch.Tensor):\n",
        "            images = images.to(device)\n",
        "            images = images.detach().cpu().numpy()\n",
        "        images = images.astype(np.float32)\n",
        "        if images.ndim == 4:\n",
        "            images = images.reshape(images.shape[0], -1)\n",
        "        elif images.ndim == 3:\n",
        "            images = images.reshape(images.shape[0], -1)\n",
        "        return normalize(images)\n",
        "\n",
        "    real_vecs = preprocess(real_images)\n",
        "    gen_vecs = preprocess(generated_images)\n",
        "\n",
        "    nn_real = NearestNeighbors(n_neighbors=k).fit(real_vecs)\n",
        "    dists_real_to_gen, _ = nn_real.kneighbors(gen_vecs)\n",
        "    precision = np.mean(np.min(dists_real_to_gen, axis=1) < eps)\n",
        "\n",
        "    nn_gen = NearestNeighbors(n_neighbors=k).fit(gen_vecs)\n",
        "    dists_gen_to_real, _ = nn_gen.kneighbors(real_vecs)\n",
        "    recall = np.mean(np.min(dists_gen_to_real, axis=1) < eps)\n",
        "\n",
        "    return precision, recall\n",
        "\n",
        "def evaluate_gan(gen_images, classifier, real_data):\n",
        "    classifier = classifier.to(device)\n",
        "\n",
        "    fake = gen_images\n",
        "    if fake.ndim == 3:\n",
        "        fake = fake[:, None, :, :]\n",
        "    elif fake.shape[1] != 1:\n",
        "        fake = fake[:, :1, :, :]\n",
        "\n",
        "    real_feats = get_classifier_features(classifier, real_data)\n",
        "    fake_feats = get_classifier_features(classifier, fake)\n",
        "\n",
        "    prec, rec = compute_precision_recall(real_data, fake, eps=0.4)\n",
        "    fid = compute_fid(real_feats, fake_feats)\n",
        "\n",
        "    return {\"Precision\": prec, \"Recall\": rec, \"FID\": fid}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Id44O6Om0Ytp",
        "outputId": "2c3accee-7b80-4340-9304-9c6d7bdc02ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50] | D Loss: 0.8522 | G Loss: 1.2559\n",
            "Epoch [2/50] | D Loss: 1.1778 | G Loss: 0.7849\n",
            "Epoch [3/50] | D Loss: 1.1673 | G Loss: 0.9453\n",
            "Epoch [4/50] | D Loss: 1.2490 | G Loss: 0.8069\n",
            "Epoch [5/50] | D Loss: 1.3686 | G Loss: 0.8480\n",
            "Epoch [6/50] | D Loss: 1.3036 | G Loss: 0.7776\n",
            "Epoch [7/50] | D Loss: 1.2714 | G Loss: 0.8059\n",
            "Epoch [8/50] | D Loss: 1.2598 | G Loss: 0.8056\n",
            "Epoch [9/50] | D Loss: 1.3428 | G Loss: 0.7431\n",
            "Epoch [10/50] | D Loss: 1.3213 | G Loss: 0.7802\n",
            "Epoch [11/50] | D Loss: 1.2911 | G Loss: 0.7459\n",
            "Epoch [12/50] | D Loss: 1.3398 | G Loss: 0.7654\n",
            "Epoch [13/50] | D Loss: 1.3498 | G Loss: 0.7475\n",
            "Epoch [14/50] | D Loss: 1.3169 | G Loss: 0.7872\n",
            "Epoch [15/50] | D Loss: 1.3141 | G Loss: 0.7487\n",
            "Epoch [16/50] | D Loss: 1.3070 | G Loss: 0.7484\n",
            "Epoch [17/50] | D Loss: 1.3725 | G Loss: 0.7481\n",
            "Epoch [18/50] | D Loss: 1.3544 | G Loss: 0.7346\n",
            "Epoch [19/50] | D Loss: 1.3466 | G Loss: 0.6983\n",
            "Epoch [20/50] | D Loss: 1.3598 | G Loss: 0.7734\n",
            "Epoch [21/50] | D Loss: 1.3661 | G Loss: 0.7204\n",
            "Epoch [22/50] | D Loss: 1.3386 | G Loss: 0.6978\n",
            "Epoch [23/50] | D Loss: 1.3348 | G Loss: 0.7802\n",
            "Epoch [24/50] | D Loss: 1.3637 | G Loss: 0.8392\n",
            "Epoch [25/50] | D Loss: 1.3786 | G Loss: 0.6771\n",
            "Epoch [26/50] | D Loss: 1.3418 | G Loss: 0.6568\n",
            "Epoch [27/50] | D Loss: 1.3800 | G Loss: 0.6931\n",
            "Epoch [28/50] | D Loss: 1.3601 | G Loss: 0.7664\n",
            "Epoch [29/50] | D Loss: 1.3594 | G Loss: 0.7976\n",
            "Epoch [30/50] | D Loss: 1.3797 | G Loss: 0.7413\n",
            "Epoch [31/50] | D Loss: 1.3362 | G Loss: 0.6837\n",
            "Epoch [32/50] | D Loss: 1.3717 | G Loss: 0.6649\n",
            "Epoch [33/50] | D Loss: 1.3648 | G Loss: 0.6807\n",
            "Epoch [34/50] | D Loss: 1.3322 | G Loss: 0.6913\n",
            "Epoch [35/50] | D Loss: 1.3437 | G Loss: 0.7293\n",
            "Epoch [36/50] | D Loss: 1.3436 | G Loss: 0.7829\n",
            "Epoch [37/50] | D Loss: 1.3858 | G Loss: 0.7302\n",
            "Epoch [38/50] | D Loss: 1.3797 | G Loss: 0.7768\n",
            "Epoch [39/50] | D Loss: 1.3786 | G Loss: 0.6838\n",
            "Epoch [40/50] | D Loss: 1.3640 | G Loss: 0.7738\n",
            "Epoch [41/50] | D Loss: 1.3660 | G Loss: 0.7337\n",
            "Epoch [42/50] | D Loss: 1.3833 | G Loss: 0.6749\n",
            "Epoch [43/50] | D Loss: 1.3407 | G Loss: 0.7534\n",
            "Epoch [44/50] | D Loss: 1.3609 | G Loss: 0.7240\n",
            "Epoch [45/50] | D Loss: 1.3612 | G Loss: 0.7107\n",
            "Epoch [46/50] | D Loss: 1.3690 | G Loss: 0.7035\n",
            "Epoch [47/50] | D Loss: 1.3910 | G Loss: 0.7794\n",
            "Epoch [48/50] | D Loss: 1.3730 | G Loss: 0.7365\n",
            "Epoch [49/50] | D Loss: 1.3635 | G Loss: 0.7540\n",
            "Epoch [50/50] | D Loss: 1.3828 | G Loss: 0.7727\n"
          ]
        }
      ],
      "source": [
        "G = Generator(z_dim=100, img_channels=1)\n",
        "D = Discriminator(img_channels=1)\n",
        "\n",
        "trained_G = train_BasicGAN(\n",
        "    generator=G,\n",
        "    discriminator=D,\n",
        "    dataloader=train_loader,\n",
        "    lr=0.0002,\n",
        "    latent_dim=100,\n",
        "    n_epochs=50\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wHWA9X60Ytp"
      },
      "outputs": [],
      "source": [
        "gen_images=generate_BasicGAN(G, num_samples=1000, plotit=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQZsXffm0Ytp",
        "outputId": "363532e1-f98a-4d11-d030-f6e56da5b28a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-29-c54628ec363c>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  batch = torch.tensor(data[i:i+batch_size], dtype=torch.float32, device=device)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'Precision': np.float64(0.374),\n",
              " 'Recall': np.float64(0.371),\n",
              " 'FID': np.float64(142.83780519641408)}"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = {}\n",
        "results[\"BasicGAN\"] = evaluate_gan(gen_images, classifier, real_data=X_mnist[:1000])\n",
        "results[\"BasicGAN\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hze9KxZ_0Ytq"
      },
      "source": [
        "DIA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rq1wLCLb9Vj3"
      },
      "outputs": [],
      "source": [
        "def safe_tensor_conversion(data):\n",
        "    if not isinstance(data, torch.Tensor):\n",
        "        return torch.tensor(data, dtype=torch.float32)\n",
        "    return data.clone().detach().float()\n",
        "\n",
        "def train_DiaGAN(generator, discriminator, data, lr=0.0005, latent_dim=100, n_epochs=200,\n",
        "                 phase1_ratio=0.9, batch_size=128, window_size=25, k=1.0,\n",
        "                 min_clip=0.01, max_ratio=50):\n",
        "\n",
        "    generator = generator.to(device)\n",
        "    discriminator = discriminator.to(device)\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    data = safe_tensor_conversion(data)\n",
        "    tensor_data = data.to(device)\n",
        "\n",
        "    is_image = (data.ndim > 2)\n",
        "    conv_mode = any(isinstance(m, nn.Conv2d) for m in discriminator.modules())\n",
        "    dataset_size = len(tensor_data)\n",
        "    ldr_dict = defaultdict(list)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        in_phase1 = epoch < int(phase1_ratio * n_epochs)\n",
        "\n",
        "        if in_phase1:\n",
        "            sampler = torch.utils.data.RandomSampler(tensor_data)\n",
        "        else:\n",
        "            scores = []\n",
        "            for i in range(dataset_size):\n",
        "                ldrs = np.array(ldr_dict[i][-window_size:])\n",
        "                if len(ldrs) == 0:\n",
        "                    scores.append(1.0)\n",
        "                else:\n",
        "                    ldrm = np.mean(ldrs)\n",
        "                    ldrv = np.var(ldrs)\n",
        "                    score = ldrm + k * np.sqrt(ldrv)\n",
        "                    scores.append(score)\n",
        "\n",
        "            scores = np.clip(scores, a_min=min_clip, a_max=min_clip * max_ratio)\n",
        "            probs = scores / scores.sum()\n",
        "            sampler = WeightedRandomSampler(probs, num_samples=dataset_size, replacement=True)\n",
        "\n",
        "        dataloader = DataLoader(TensorDataset(tensor_data), batch_size=batch_size, sampler=sampler)\n",
        "\n",
        "        for real_batch, in dataloader:\n",
        "            imgs = real_batch.to(device)\n",
        "            bs = imgs.size(0)\n",
        "\n",
        "            real_labels = torch.ones(bs, 1, device=device)\n",
        "            fake_labels = torch.zeros(bs, 1, device=device)\n",
        "\n",
        "            z = torch.randn(bs, latent_dim, device=device)\n",
        "            fake_imgs = generator(z)\n",
        "\n",
        "            real_input = imgs if conv_mode else imgs.view(bs, -1)\n",
        "            fake_input = fake_imgs if conv_mode else fake_imgs.view(bs, -1)\n",
        "\n",
        "            d_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "            d_optimizer.zero_grad()\n",
        "            real_out = discriminator(real_input)\n",
        "            fake_out = discriminator(fake_input.detach())\n",
        "            d_loss = criterion(real_out, real_labels) + criterion(fake_out, fake_labels)\n",
        "            d_loss.backward()\n",
        "            d_optimizer.step()\n",
        "\n",
        "            g_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "            g_optimizer.zero_grad()\n",
        "            fake_out = discriminator(fake_input)\n",
        "            g_loss = criterion(fake_out, real_labels)\n",
        "            g_loss.backward()\n",
        "            g_optimizer.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            D_x = discriminator(tensor_data if conv_mode else tensor_data.view(len(tensor_data), -1)).squeeze()\n",
        "            D_x_sigmoid = torch.sigmoid(D_x)\n",
        "            LDR_x = torch.log(D_x_sigmoid / (1 - D_x_sigmoid + 1e-6)).cpu().numpy()\n",
        "            for i in range(dataset_size):\n",
        "                ldr_dict[i].append(LDR_x[i])\n",
        "\n",
        "        if epoch % 2 == 0:\n",
        "            print(f\"[Epoch {epoch}] D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f}\")\n",
        "\n",
        "    return generator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9QMmAQf0Ytq",
        "outputId": "6d1bf917-7cc3-45a7-8d7a-b0633196c640"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 0] D Loss: 1.3173 | G Loss: 0.6141\n",
            "[Epoch 2] D Loss: 1.3033 | G Loss: 0.6896\n",
            "[Epoch 4] D Loss: 1.3112 | G Loss: 0.7080\n",
            "[Epoch 6] D Loss: 1.2864 | G Loss: 0.8916\n",
            "[Epoch 8] D Loss: 1.3825 | G Loss: 0.7072\n",
            "[Epoch 10] D Loss: 1.3041 | G Loss: 0.8523\n",
            "[Epoch 12] D Loss: 1.3243 | G Loss: 0.8208\n",
            "[Epoch 14] D Loss: 1.3543 | G Loss: 0.7682\n",
            "[Epoch 16] D Loss: 1.3582 | G Loss: 0.8096\n",
            "[Epoch 18] D Loss: 1.4081 | G Loss: 0.7545\n",
            "[Epoch 20] D Loss: 1.3605 | G Loss: 0.7602\n",
            "[Epoch 22] D Loss: 1.3318 | G Loss: 0.7363\n",
            "[Epoch 24] D Loss: 1.3429 | G Loss: 0.7864\n",
            "[Epoch 26] D Loss: 1.3103 | G Loss: 0.7300\n",
            "[Epoch 28] D Loss: 1.3442 | G Loss: 0.7462\n",
            "[Epoch 30] D Loss: 1.3361 | G Loss: 0.8141\n",
            "[Epoch 32] D Loss: 1.3410 | G Loss: 0.7386\n",
            "[Epoch 34] D Loss: 1.3032 | G Loss: 0.8371\n",
            "[Epoch 36] D Loss: 1.3154 | G Loss: 0.7097\n",
            "[Epoch 38] D Loss: 1.3334 | G Loss: 0.7810\n",
            "[Epoch 40] D Loss: 1.3144 | G Loss: 0.6995\n",
            "[Epoch 42] D Loss: 1.2913 | G Loss: 0.8007\n",
            "[Epoch 44] D Loss: 1.3144 | G Loss: 0.7053\n",
            "[Epoch 46] D Loss: 1.3059 | G Loss: 0.7074\n",
            "[Epoch 48] D Loss: 1.3331 | G Loss: 0.8133\n"
          ]
        }
      ],
      "source": [
        "diaG = Generator(z_dim=100, img_channels=1)\n",
        "diaD = Discriminator(img_channels=1)\n",
        "\n",
        "trained_diaG = train_DiaGAN(\n",
        "    generator=diaG,\n",
        "    discriminator=diaD,\n",
        "    data=X_mnist,\n",
        "    lr=0.0002,\n",
        "    latent_dim=100,\n",
        "    n_epochs=50,\n",
        "    phase1_ratio=0.5,\n",
        "    k=0.3,\n",
        "    batch_size=64\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYVvR-Yz0Ytq",
        "outputId": "24317dfe-610d-47b9-dde5-d2d03f366981"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-c54628ec363c>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  batch = torch.tensor(data[i:i+batch_size], dtype=torch.float32, device=device)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'Precision': np.float64(0.361),\n",
              " 'Recall': np.float64(0.401),\n",
              " 'FID': np.float64(166.76698073824383)}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gen_images_dia=generate_BasicGAN(diaG, num_samples=1000)\n",
        "results = {}\n",
        "results[\"DiaGAN\"] = evaluate_gan(gen_images_dia, classifier, real_data=X_mnist[:1000])\n",
        "results[\"DiaGAN\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnigXXMH0Ytq"
      },
      "source": [
        "BASIC + DRS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3rzbo90qCqJv"
      },
      "outputs": [],
      "source": [
        "def apply_DRS(generator, real_data, z_dim=100, num_gen=10000, batch_size=128, n_epochs=5):\n",
        "    generator = generator.to(device)\n",
        "\n",
        "    # Prepare real data\n",
        "    if not isinstance(real_data, torch.Tensor):\n",
        "        real_tensor = torch.tensor(real_data, dtype=torch.float32)\n",
        "    else:\n",
        "        real_tensor = real_data.clone().detach().float()\n",
        "\n",
        "    real_tensor = real_tensor.to(device)\n",
        "    real_labels = torch.ones(len(real_tensor), 1, device=device)\n",
        "\n",
        "    # Generate fake data\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(num_gen, z_dim, device=device)\n",
        "        fake_tensor = generator(z).detach()\n",
        "    fake_labels = torch.zeros(len(fake_tensor), 1, device=device)\n",
        "\n",
        "    # Combine real and fake\n",
        "    combined_data = torch.cat([real_tensor, fake_tensor], dim=0)\n",
        "    combined_labels = torch.cat([real_labels, fake_labels], dim=0)\n",
        "    loader = DataLoader(TensorDataset(combined_data, combined_labels), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Train auxiliary discriminator\n",
        "    aux_disc = Discriminator(img_channels=1).to(device)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = torch.optim.Adam(aux_disc.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "    print(\"Training auxiliary discriminator for DRS...\")\n",
        "    aux_disc.train()\n",
        "    for epoch in range(n_epochs):\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            out = aux_disc(x)\n",
        "            loss = criterion(out, y)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f\"[Epoch {epoch+1}] Aux D Loss: {loss.item():.4f}\")\n",
        "\n",
        "    aux_disc.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = aux_disc(fake_tensor).squeeze()\n",
        "        probs = torch.sigmoid(logits)\n",
        "        ldr = probs / (1 - probs + 1e-6)\n",
        "\n",
        "    # Normalize and resample with probability LDR\n",
        "    ldr_np = ldr.cpu().numpy()\n",
        "    acceptance_probs = ldr_np / ldr_np.max()\n",
        "    accept_flags = np.random.rand(len(ldr_np)) < acceptance_probs\n",
        "\n",
        "    filtered_samples = fake_tensor[accept_flags]\n",
        "    print(f\"DRS Accepted {len(filtered_samples)}/{num_gen} samples ({accept_flags.mean()*100:.2f}%)\")\n",
        "    return filtered_samples.cpu().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv1jGTqo0Ytr",
        "outputId": "3f8c7561-cc5c-4244-8921-e208606bd299"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training auxiliary discriminator for DRS...\n",
            "[Epoch 1] Aux D Loss: 0.2668\n",
            "[Epoch 2] Aux D Loss: 0.3534\n",
            "[Epoch 3] Aux D Loss: 0.3987\n",
            "[Epoch 4] Aux D Loss: 0.2601\n",
            "[Epoch 5] Aux D Loss: 0.3391\n",
            "DRS Accepted 224/10000 samples (2.24%)\n"
          ]
        }
      ],
      "source": [
        "filtered_samples_basic = apply_DRS(\n",
        "    generator=G,\n",
        "    real_data=X_mnist,  # shape: (60000, 1, 28, 28)\n",
        "    z_dim=100,\n",
        "    num_gen=10000\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlLrwHSB0Ytr",
        "outputId": "927e6c89-b754-4d40-c583-ed2a61e83115"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-29-c54628ec363c>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  batch = torch.tensor(data[i:i+batch_size], dtype=torch.float32, device=device)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'Precision': np.float64(0.15178571428571427),\n",
              " 'Recall': np.float64(0.20535714285714285),\n",
              " 'FID': np.float64(389.9210941864924)}"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "results[\"BasicGAN + DRS\"] = evaluate_gan(filtered_samples_basic, classifier, real_data=X_mnist[:len(filtered_samples_basic)])\n",
        "results[\"BasicGAN + DRS\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWzeFQng0Ytr"
      },
      "source": [
        "DIA + DRS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcyrJgoX0Ytr",
        "outputId": "a2e9febf-6078-4947-95d8-e21128ea0e4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training auxiliary discriminator for DRS...\n",
            "[Epoch 1] Aux D Loss: 0.3708\n",
            "[Epoch 2] Aux D Loss: 0.3610\n",
            "[Epoch 3] Aux D Loss: 0.3149\n",
            "[Epoch 4] Aux D Loss: 0.3227\n",
            "[Epoch 5] Aux D Loss: 0.3413\n",
            "DRS Accepted 542/10000 samples (5.42%)\n"
          ]
        }
      ],
      "source": [
        "filtered_samples_dia = apply_DRS(\n",
        "    generator=diaG,\n",
        "    real_data=X_mnist,  # shape: (60000, 1, 28, 28)\n",
        "    z_dim=100,\n",
        "    num_gen=10000\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCtmJQxn0Yts",
        "outputId": "7ae7673a-ebb4-4d37-87ed-ddafbe94ef41"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-c54628ec363c>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  batch = torch.tensor(data[i:i+batch_size], dtype=torch.float32, device=device)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'Precision': np.float64(0.29704797047970477),\n",
              " 'Recall': np.float64(0.3118081180811808),\n",
              " 'FID': np.float64(217.246650653262)}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results[\"DiaGAN + DRS\"] = evaluate_gan(filtered_samples_dia, classifier, real_data=X_mnist[:len(filtered_samples_dia)])\n",
        "results[\"DiaGAN + DRS\"]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "GNN_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
